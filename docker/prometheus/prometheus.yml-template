# Example configuration. Please have a look at this article:
# https://www.confluent.io/blog/bring-your-own-monitoring-with-confluent-cloud/
# Customize this template and copy it to "prometheus.yml", then run docker compose
global:
  scrape_interval:     1m # By default, scrape targets every 15 seconds.
  evaluation_interval: 1m # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
#  external_labels:
#      monitor: 'my-project'

# # Load and evaluate rules in this file every 'evaluation_interval' seconds.
# rule_files:
#   - 'alert.rules'

# # alert
# alerting:
#   alertmanagers:
#   - scheme: http
#     static_configs:
#     - targets:
#       - "alertmanager:9093"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 15s
    static_configs:
         - targets: ['localhost:9090']
  - job_name: 'Confluent Cloud'
    scrape_interval: 1m
    scrape_timeout: 1m
    honor_timestamps: true
    static_configs:
      - targets:
        - 'api.telemetry.confluent.cloud'
    scheme: https
    basic_auth:
      username: 'CONFLUENT-CLOUD-USERNAME'
      password: 'CONFLUENT-CLOUD-PASSWORD'
    metrics_path: '/v2/metrics/cloud/export'
    params:
      "resource.kafka.id":
        - 'lkc-1234' # CUSTOMIZE ME
        - 'lkc-2345' # CUSTOMIZE ME
      # "resource.connector.id":
      #   - lcc-1234
      #   - lcc-2345
